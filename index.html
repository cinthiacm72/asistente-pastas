<!DOCTYPE html>
<html lang="es">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Asistente Voz Pasta - Wit.ai Vanilla (iOS compatible)</title>
<style>
  body { font-family: Arial, sans-serif; padding: 2rem; max-width: 600px; margin: auto; }
  button { font-size: 1.2rem; padding: 0.7rem 1.5rem; }
  #status { margin-top: 1rem; font-weight: bold; white-space: pre-wrap; }
  #response { margin-top: 1rem; white-space: pre-wrap; }
</style>
</head>
<body>

<h1>Asistente de Voz - Pastas</h1>
<button id="startBtn">Iniciar conversación</button>

<div id="status">Presiona "Iniciar conversación" para comenzar</div>
<div id="response"></div>

<script>

  if ('SpeechRecognition' in window || 'webkitSpeechRecognition' in window) {
  console.log("SpeechRecognition disponible");
} else {
  console.log("SpeechRecognition NO disponible, solo grabación audio");
}

  
(() => {
  const WIT_TOKEN = '72OKU3ULAQHNR3CMRMQ5DVQGKNIUG7LK'; // Tu token Wit.ai

  const startBtn = document.getElementById('startBtn');
  const statusEl = document.getElementById('status');
  const responseEl = document.getElementById('response');

  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
  const isSpeechRecSupported = !!SpeechRecognition;

  let recognition;
  let isListening = false;

  let mediaRecorder;
  let chunks = [];

  // Función para enviar texto a Wit.ai
  async function sendTextToWit(text) {
    statusEl.textContent = 'Enviando texto a Wit.ai...';
    const url = `https://api.wit.ai/message?v=20230606&q=${encodeURIComponent(text)}`;
    try {
      const res = await fetch(url, {
        headers: {
          Authorization: `Bearer ${WIT_TOKEN}`
        }
      });
      if (!res.ok) {
        statusEl.textContent = 'Error al conectar con Wit.ai';
        return null;
      }
      const data = await res.json();
      return data;
    } catch (e) {
      statusEl.textContent = 'Error en la petición a Wit.ai';
      return null;
    }
  }

  // Función para enviar audio a Wit.ai (para iOS)
  async function sendAudioToWit(blob) {
    statusEl.textContent = 'Enviando audio a Wit.ai...';

    try {
      const arrayBuffer = await blob.arrayBuffer();
      const res = await fetch('https://api.wit.ai/speech?v=20230606', {
        method: 'POST',
        headers: {
          Authorization: `Bearer ${WIT_TOKEN}`,
          'Content-Type': blob.type
        },
        body: arrayBuffer
      });
      if (!res.ok) {
        statusEl.textContent = `Error al enviar audio a Wit.ai (status ${res.status})`;
        return null;
      }
      const data = await res.json();
      return data;
    } catch (e) {
      statusEl.textContent = 'Error en la petición de audio a Wit.ai';
      return null;
    }
  }

  // Función para hablar (Text to Speech)
  function speak(text) {
    if (!('speechSynthesis' in window)) return;
    const utterance = new SpeechSynthesisUtterance(text);
    window.speechSynthesis.speak(utterance);
  }

  // Función para manejar respuesta de Wit.ai
  function handleWitResponse(data) {
    console.log('Wit.ai response:', data);

    const text = data.text || '';
    let intent = null;
    if (data.intents && data.intents.length > 0) {
      intent = data.intents[0].name;
    }

    responseEl.textContent = `Intención: ${intent || 'No detectada'}\nTexto: ${text}`;

    let answer = '';

    if (intent === 'about_brand') {
      answer = 'Somos una marca dedicada a las mejores pastas italianas artesanales.';
    } else if (intent === 'get_recipe') {
      answer = 'Aquí tienes una receta fácil: Pasta con salsa de tomate y albahaca.';
    } else {
      answer = 'Lo siento, no entendí tu pregunta. ¿Puedes repetir?';
    }

    responseEl.textContent += `\n\nRespuesta: ${answer}`;
    speak(answer);
  }

  // Función para iniciar SpeechRecognition (Chrome, Android)
  function startSpeechRecognition() {
    if (isListening) {
      recognition.stop();
      return;
    }

    recognition = new SpeechRecognition();
    recognition.lang = 'es-ES';
    recognition.interimResults = false;
    recognition.maxAlternatives = 1;

    recognition.onstart = () => {
      isListening = true;
      startBtn.textContent = 'Detener escucha';
      statusEl.textContent = 'Escuchando...';
      responseEl.textContent = '';
    };

    recognition.onresult = async (event) => {
      const text = event.results[0][0].transcript;
      statusEl.textContent = `Reconocido: "${text}"`;
      const witResponse = await sendTextToWit(text);
      if (witResponse) handleWitResponse(witResponse);
    };

    recognition.onerror = (event) => {
      statusEl.textContent = `Error: ${event.error}`;
      isListening = false;
      startBtn.textContent = 'Iniciar conversación';
    };

    recognition.onend = () => {
      isListening = false;
      startBtn.textContent = 'Iniciar conversación';
      statusEl.textContent = 'Escucha finalizada';
    };

    recognition.start();
  }

  // Función para grabar audio y enviar a Wit.ai (Safari iOS)
  async function startAudioRecording() {
    if (mediaRecorder && mediaRecorder.state === 'recording') {
      mediaRecorder.stop();
      startBtn.textContent = 'Iniciar conversación';
      return;
    }

    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
      statusEl.textContent = 'Grabación de audio no soportada en este navegador';
      return;
    }

    const constraints = { audio: true };

    try {
      const stream = await navigator.mediaDevices.getUserMedia(constraints);

      chunks = [];
      mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/mp4'  // Cambiado para mejor compatibilidad en iOS
      });

      mediaRecorder.ondataavailable = (e) => chunks.push(e.data);

      mediaRecorder.onstart = () => {
        statusEl.textContent = 'Grabando audio... Presiona el botón para detener';
        startBtn.textContent = 'Detener grabación';
        responseEl.textContent = '';
      };

      mediaRecorder.onstop = async () => {
        const blob = new Blob(chunks, { type: 'audio/mp4' });
        chunks = [];
        const witResponse = await sendAudioToWit(blob);
        if (witResponse) handleWitResponse(witResponse);
      };

      mediaRecorder.start();
    } catch (err) {
      statusEl.textContent = 'Error al acceder al micrófono o iniciar grabación';
      console.error(err);
    }
  }

  startBtn.addEventListener('click', () => {
    if (isSpeechRecSupported) {
      startSpeechRecognition();
    } else {
      startAudioRecording();
    }
  });

})();
</script>

</body>
</html>



<!-- <!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Asistente de Pastas</title>
  <link rel="stylesheet" href="styles.css" />
</head>
<body>
  
  <div class="container">
    <img src="https://www.shutterstock.com/image-vector/silhouette-monochrome-dish-hot-spaghetti-260nw-520318474.jpg" alt="Logo de Asistente Pastas" class="logo" />
    <h1>Asistente de Pastas Italianas</h1>
    <p>Presiona el botón y háblame. Por ejemplo: <em>"¿Qué productos ofrecen?"</em> o <em>"Sugiéreme una receta con fettuccine."</em></p>
    
    <button id="hablarBtn">🎤 Hablar</button>
    
    <div class="respuesta" id="respuesta"></div>
  </div>

  <script src="main.js"></script>
</body>
</html> -->
